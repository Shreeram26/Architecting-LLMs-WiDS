{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15aa6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442510c5",
   "metadata": {},
   "source": [
    "Trying a 3-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86572019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "words=open('english_words.txt','r').read().splitlines()\n",
    "random_seed=42\n",
    "random.seed(random_seed)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb756d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(set(''.join(words)))\n",
    "chars.append('.')\n",
    "chars.append('_')\n",
    "vocab_size=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbd1c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi={s:i for i,s in enumerate(chars)}\n",
    "itos={i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e166cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af203701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_masked_dataset(words):\n",
    "    X,Y=[],[]\n",
    "\n",
    "    for w in words:\n",
    "        w='.' + w + '.'\n",
    "        for i in range(1,len(w)-1):\n",
    "            left=w[i-1]\n",
    "            mid=w[i]\n",
    "            right=w[i+1]\n",
    "\n",
    "            if mid=='.':\n",
    "                continue\n",
    "\n",
    "            X.append([stoi[left],stoi[right]])\n",
    "            Y.append(stoi[mid])\n",
    "\n",
    "    return torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7d3cadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([65259, 2]), torch.Size([65259]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y=build_masked_dataset(words)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "876a1f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: l\n",
      "Right: s\n",
      "Target: e\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print(\"Left:\", itos[X[i][0].item()])\n",
    "print(\"Right:\", itos[X[i][1].item()])\n",
    "print(\"Target:\", itos[Y[i].item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5f802e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".oogle.\n"
     ]
    }
   ],
   "source": [
    "test_word = \"_oogle\"\n",
    "w = \".\" + test_word.replace(\"_\", \"\") + \".\"\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71e625ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.randn((vocab_size,vocab_size,vocab_size),requires_grad=True)  # W[left, right, mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02596b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=W[X[:,0],X[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2fcb402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65259, 28])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c897c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=F.cross_entropy(logits,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3925cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.812284231185913"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee382125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: 3.812284231185913\n",
      "Step 25: 2.9119510650634766\n",
      "Step 50: 2.6048758029937744\n",
      "Step 75: 2.436429262161255\n",
      "Step 100: 2.331171989440918\n",
      "Step 125: 2.259284257888794\n",
      "Step 150: 2.2069544792175293\n",
      "Step 175: 2.167023181915283\n",
      "Step 200: 2.13547682762146\n",
      "Step 225: 2.1098973751068115\n",
      "Step 250: 2.0887343883514404\n",
      "Step 275: 2.07094144821167\n"
     ]
    }
   ],
   "source": [
    "lr=50\n",
    "\n",
    "for step in range(300):\n",
    "    logits=W[X[:,0],X[:,1]]\n",
    "    loss=F.cross_entropy(logits,Y)\n",
    "\n",
    "    W.grad=None\n",
    "    loss.backward()\n",
    "    W.data-=lr*W.grad\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f'Step {step}: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6245c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_one_blank(word):\n",
    "    w = '.' + word + '.'\n",
    "    i = w.index('_')\n",
    "\n",
    "    left = w[i - 1]\n",
    "    right = w[i + 1]\n",
    "\n",
    "    logits = W[stoi[left], stoi[right]]\n",
    "    probs = logits.softmax(dim=0)\n",
    "    ix = torch.argmax(probs).item()\n",
    "\n",
    "    return word.replace('_', itos[ix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9221528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goo_le → goolle\n",
      "regula_ions → regulations\n",
      "wait_r → waiter\n",
      "raz_r → razkr\n",
      "b_tt_r → buttur\n",
      "compu_er → compurer\n",
      "develo_ment → develomment\n",
      "pyth_n → pythan\n"
     ]
    }
   ],
   "source": [
    "tests = [\"goo_le\", \"regula_ions\", \"wait_r\", \"raz_r\", \"b_tt_r\", \"compu_er\", \"develo_ment\", \"pyth_n\"]\n",
    "\n",
    "for t in tests:\n",
    "    print(t, \"→\", fill_one_blank(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91c3e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_predictions(word, k=5):\n",
    "    w = '.' + word + '.'\n",
    "    i = w.index('_')\n",
    "\n",
    "    left = w[i - 1]\n",
    "    right = w[i + 1]\n",
    "\n",
    "    logits = W[stoi[left], stoi[right]]\n",
    "    probs = logits.softmax(dim=0)\n",
    "    vals, idxs = torch.topk(probs, k)\n",
    "\n",
    "    return [(itos[i.item()], v.item()) for i, v in zip(idxs, vals)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afbde283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l', 0.4272497594356537),\n",
       " ('o', 0.1186051294207573),\n",
       " ('u', 0.07536370307207108),\n",
       " ('w', 0.03468449413776398),\n",
       " ('b', 0.02674558386206627)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_predictions(\"goo_le\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb4e2b1",
   "metadata": {},
   "source": [
    "Trying a 5-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9a25ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_5gram_masked_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        w = '..' + w + '..'\n",
    "        for i in range(2, len(w) - 2):\n",
    "            mid = w[i]\n",
    "            if mid == '.':\n",
    "                continue\n",
    "\n",
    "            X.append([\n",
    "                stoi[w[i-2]],  # left2\n",
    "                stoi[w[i-1]],  # left1\n",
    "                stoi[w[i+1]],  # right1\n",
    "                stoi[w[i+2]]   # right2\n",
    "            ])\n",
    "            Y.append(stoi[mid])\n",
    "\n",
    "    return torch.tensor(X), torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2064e3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([65259, 4]), torch.Size([65259]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = build_5gram_masked_dataset(words)\n",
    "\n",
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bab2c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . _ l e → b\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\n",
    "    itos[X[i][0].item()],\n",
    "    itos[X[i][1].item()],\n",
    "    \"_\",\n",
    "    itos[X[i][2].item()],\n",
    "    itos[X[i][3].item()],\n",
    "    \"→\",\n",
    "    itos[Y[i].item()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e5eb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((vocab_size, vocab_size, vocab_size, vocab_size, vocab_size), requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11893e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = W[\n",
    "    X[:,0],  # left2\n",
    "    X[:,1],  # left1\n",
    "    X[:,2],  # right1\n",
    "    X[:,3]   # right2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "052d15ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.1773359775543213\n",
      "50 2.074345827102661\n",
      "100 1.9848856925964355\n",
      "150 1.9063074588775635\n",
      "200 1.836618423461914\n",
      "250 1.7742846012115479\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "lr = 100\n",
    "\n",
    "for step in range(300):\n",
    "    logits = W[X[:,0], X[:,1], X[:,2], X[:,3]]\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data -= lr * W.grad\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        print(step, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccbe14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_one_blank_5gram(word):\n",
    "    w = '..' + word + '..'\n",
    "    i = w.index('_')\n",
    "\n",
    "    l2 = w[i-2]\n",
    "    l1 = w[i-1]\n",
    "    r1 = w[i+1]\n",
    "    r2 = w[i+2]\n",
    "\n",
    "    logits = W[\n",
    "        stoi[l2],\n",
    "        stoi[l1],\n",
    "        stoi[r1],\n",
    "        stoi[r2]\n",
    "    ]\n",
    "    probs = logits.softmax(dim=0)\n",
    "    ix = torch.argmax(probs).item()\n",
    "\n",
    "    return word.replace('_', itos[ix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3834d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goo_le → goojle\n",
      "regula_ions → regulations\n",
      "wait_r → waitor\n",
      "b_tt_r → buttur\n",
      "compu_er → computer\n",
      "develo_ment → development\n",
      "pyth_n → python\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"goo_le\",\n",
    "    \"regula_ions\",\n",
    "    \"wait_r\",\n",
    "    \"b_tt_r\",\n",
    "    \"compu_er\",\n",
    "    \"develo_ment\",\n",
    "    \"pyth_n\"\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(t, \"→\", fill_one_blank_5gram(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3cb33",
   "metadata": {},
   "source": [
    "We see phonetic errors, but overall the model predicts good things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_predictions(word, k=5):\n",
    "    w = '.' + word + '.'\n",
    "    i = w.index('_')\n",
    "\n",
    "    left = w[i - 1]\n",
    "    right = w[i + 1]\n",
    "\n",
    "    logits = W[stoi[left], stoi[right]]\n",
    "    probs = logits.softmax(dim=0)\n",
    "    vals, idxs = torch.topk(probs, k)\n",
    "\n",
    "    return [(itos[i.item()], v.item()) for i, v in zip(idxs, vals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aefca666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('j', 0.292244553565979), ('u', 0.12169970571994781), ('e', 0.08292999118566513), ('o', 0.061494868248701096), ('g', 0.055679213255643845)]\n"
     ]
    }
   ],
   "source": [
    "w = '..' + 'goo_le' + '..'\n",
    "i = w.index('_')\n",
    "\n",
    "l2 = w[i-2]\n",
    "l1 = w[i-1]\n",
    "r1 = w[i+1]\n",
    "r2 = w[i+2]\n",
    "\n",
    "logits = W[\n",
    "        stoi[l2],\n",
    "        stoi[l1],\n",
    "        stoi[r1],\n",
    "        stoi[r2]]\n",
    "probs = logits.softmax(dim=0)\n",
    "vals, idxs = torch.topk(probs, 5)\n",
    "print([(itos[i.item()], v.item()) for i, v in zip(idxs, vals)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
